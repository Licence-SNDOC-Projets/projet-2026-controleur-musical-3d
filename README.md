# AVIGNON UNIVERSIT√â | LICENCE PRO SN DOC
**La Salle Avignon ‚Äì Fr√®res des √âcoles Chr√©tiennes**

---

# üéµ FICHE PROJET 2026 : CONTR√îLEUR MUSICAL 3D SANS CONTACT

**Date :** 05 D√©cembre 2025
**Statut :** Lancement Officiel
**Niveau :** Expert (Traitement du signal + Temps r√©el)

## 1. Composition de l'√âquipe
Ce projet est attribu√© au groupe de travail suivant :
* **Louis RAFFIN** 
* **Axelle LERENARD** 
* **Yann TOLOSANO**

---

## 2. Pr√©sentation g√©n√©rale du syst√®me

### Contexte
Depuis l'invention du Th√©r√©mine en 1920, la musique "sans contact" fascine. Aujourd'hui, avec l'essor de la M.A.O. (Musique Assist√©e par Ordinateur) et les besoins d'hygi√®ne ou d'accessibilit√© (pour personnes √† mobilit√© r√©duite), cr√©er des interfaces de contr√¥le gestuel devient un enjeu technologique majeur.
Ce projet vise √† cr√©er un instrument ou une interface de contr√¥le musical invisible, pilot√© uniquement par la position des mains dans l'espace.

### Objectif du Projet
Cr√©er une interface "AirMusic" capable de transformer des mouvements dans le vide en instructions musicales pr√©cises.
Le but ultime est l'impl√©mentation du protocole **MIDI over USB** : l'appareil ne doit pas seulement √©mettre des sons simples, mais contr√¥ler un v√©ritable logiciel de production musicale professionnel (Ableton, GarageBand, FL Studio) comme un clavier ma√Ætre standard.

### Innovation 2026 : Latence Z√©ro & Feedback
Le d√©fi principal de ce projet est la **r√©activit√©**. La latence entre le geste et le son doit √™tre imperceptible (< 20ms).
L'innovation de cette ann√©e r√©side dans l'ajout d'un **retour visuel imm√©diat** (Anneau de LEDs ou √âcran OLED) qui mat√©rialise la note jou√©e, rendant l'instrument accessible aux non-musiciens.

---

## 3. Synoptique et Architecture Technique

### A. Architecture Mat√©rielle (Hardware)
Le syst√®me transforme une grandeur physique (distance) en un protocole num√©rique musical (MIDI).

```mermaid
graph TD
    %% Styles
    classDef daw fill:#f9f,stroke:#333,stroke-width:2px;
    classDef mcu fill:#ccf,stroke:#333,stroke-width:2px;
    classDef sensor fill:#ffc,stroke:#333,stroke-width:2px;

    subgraph COMPUTER ["üíª ORDINATEUR / DAW"]
        DAW[("Logiciel MAO<br>(Ableton / FL Studio)")]:::daw
        Synth[("Synth√©tiseur Virtuel<br>(VST)")]
    end

    subgraph CONTROLLER ["üéõÔ∏è BO√éTIER CONTR√îLEUR 3D"]
        MCU{{"Microcontr√¥leur<br>(ESP32-S3 / ESP32)"}}:::mcu
        
        subgraph SENSORS ["Capteurs (Entr√©es)"]
            TOF_L[/"Main GAUCHE<br>(Contr√¥le Volume/CC)"/]:::sensor
            TOF_R[/"Main DROITE<br>(Contr√¥le Note/Pitch)"/]:::sensor
        end
        
        subgraph FEEDBACK ["Retour Visuel (Sorties)"]
            LEDs(("Anneau LED<br>(Visualisation Distance)"))
            OLED(("√âcran OLED<br>(Menu/Mode)"))
        end
    end

    %% Flux de donn√©es
    TOF_L -- "I2C/Analog (cm)" --> MCU
    TOF_R -- "I2C/Analog (cm)" --> MCU
    
    MCU -- "MIDI over USB (NoteOn / CC)" --> DAW
    DAW --> Synth
    Synth -.->|"AUDIO"| Speakers[("üîä Haut-parleurs")]
    
    MCU -- "Feedback Couleur/Intensit√©" --> LEDs
```

### B. Algorithme de Traitement du Signal
La conversion du signal brut des capteurs en note musicale stable n√©cessite un traitement algorithmique rigoureux pour √©viter le "Jitter" (saut de notes).

```mermaid
flowchart LR
    A[Capteur Brut] -->|Signal Bruit√©| B(Lissage / Moyenne Glissante)
    B --> C{Main pr√©sente ?}
    C -- Non --> D[Note OFF]
    C -- Oui --> E[Mapping]
    
    subgraph PROCESS [Transformation]
        E -->|Conversion| F[Distance cm -> Valeur 0-127]
        F --> G[Quantification]
        G -->|Force Gamme| H[Do R√© Mi Fa Sol...]
    end
    
    H --> I[Envoi Message MIDI]
    H --> J[Mise √† jour LED]
```

---

## 4. Fonctionnalit√©s & Cahier des Charges

### A. D√©tection Spatiale & Interpr√©tation (Le Geste) üëã
Le c≈ìur du projet r√©side dans la transformation d'une donn√©e brute de distance en intention musicale. L'√©quipe devra proposer une solution technique aux d√©fis suivants :
* **D√©finition des Axes (X/Y) :** Comment r√©partir intelligemment les contr√¥les ? (Ex: Axe Vertical pour le Pitch, Axe Horizontal pour le Volume/Modulation).
* **Placement des Capteurs :** Une r√©flexion approfondie est attendue sur l'agencement physique pour √©viter les zones mortes et les interf√©rences entre capteurs (Crosstalk).
* **Polyphonie :** Le syst√®me se limite-t-il √† une seule note √† la fois (Monophonie) ? Les √©tudiants devront explorer des pistes pour permettre le jeu de plusieurs notes ou d'accords (Arp√©giateur intelligent, mode "Latch", ou division de zone).

### B. Interface & Feedback Visuel
* **Anneau LED (NeoPixel) :** Doit changer de couleur (ex: du Bleu au Rouge) ou d'intensit√© en fonction de la distance de la main pour guider l'utilisateur.
* **√âcran OLED (Optionnel) :** Affichage du mode actuel (Mode Piano, Mode Batterie, Mode DJ).

### C. Connectivit√©
* **MIDI over USB :** L'appareil doit √™tre reconnu nativement ("Plug & Play") par Windows/MacOS comme un p√©riph√©rique MIDI, sans installation de driver complexe.

---

## 5. Ressources & Inspiration (Bibliographie Technique)

L'√©quipe devra s'appuyer sur les r√©f√©rences suivantes :
* **R√©f√©rence historique :** *Le Th√©r√©mine* (Wikip√©dia) pour comprendre la logique de l'oscillateur contr√¥l√© par le geste.
* **Tutoriels Techniques :**
    * *Arduino MIDI Controller (Notes and Volts)* : La ressource de r√©f√©rence pour le protocole MIDI.
    * *Adafruit VL53L5CX Guide* : Documentation pour les capteurs ToF matriciels (Multizone 8x8).
* **Composants Recommand√©s :**
    * Microcontr√¥leur : **ESP32-S3** (Recommand√© pour l'USB Natif) ou **ESP32 Standard** (Pour MIDI via Bluetooth/WiFi).
    * Capteurs : **VL53L5CX** (ToF Matrice) pour une d√©tection multi-zones pr√©cise, rempla√ßant le VL53L0X (c√¥ne trop large).

---

## 6. Jalons & Livrables Sp√©cifiques 2026

| Date | Jalon | Livrable Technique Attendu |
| :--- | :--- | :--- |
| **10 F√©vrier** | **Jalon 1 (Sp√©cifications)** | **POC MIDI.** Le syst√®me est capable d'envoyer une note simple √† l'ordinateur via USB lorsqu'on passe la main devant un capteur (sur Breadboard). |
| **14 Avril** | **Jalon 2 (Mi-parcours)** | **Prototype Fonctionnel.** Les capteurs sont fix√©s. Le code g√®re le Pitch (Main Droite) et le Volume (Main Gauche) simultan√©ment avec un d√©but de lissage du signal. |
| **19 Juin** | **Soutenance Finale** | **D√©monstration Musicale.** L'√©tudiant joue une m√©lodie reconnaissable ou contr√¥le un effet audio complexe en rythme sans latence audible. |

---

## 7. Crit√®res d'√âvaluation Sp√©cifiques

1.  **R√©activit√© (Latence) :** D√©lai imperceptible entre le geste et le son.
2.  **Stabilit√© du Signal :** L'instrument ne doit pas jouer de fausses notes si la main ne bouge pas (filtrage du bruit √©lectronique).
3.  **Ergonomie & Design :** Qualit√© du bo√Ætier (Impression 3D ou D√©coupe Laser) et int√©gration esth√©tique des LEDs.
